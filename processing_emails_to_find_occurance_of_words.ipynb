{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44375a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b1fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4534fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wordslist.csv',header=0)\n",
    "words = df['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0041e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cd73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_in_str = \"emails/\"\n",
    "directory = os.fsencode(directory_in_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4389ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"frequency.csv\",\"w+\")\n",
    "for i in words:\n",
    "    f.write(str(i) + ',')\n",
    "f.write('output')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0c7ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 8100\n",
      "Done 8200\n",
      "Done 8300\n",
      "Done 8400\n",
      "Done 8500\n",
      "Done 8600\n",
      "Done 8700\n",
      "Done 8800\n",
      "Done 8900\n",
      "Done 9000\n",
      "Done 9100\n",
      "Done 9200\n",
      "Done 9300\n",
      "Done 9400\n",
      "Done 9500\n",
      "Done 9600\n",
      "Done 9700\n",
      "Done 9800\n",
      "Done 9900\n",
      "Done 10000\n",
      "Done 10100\n",
      "Done 10200\n",
      "Done 10300\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for file in os.listdir(directory):\n",
    "    file = file.decode(\"utf-8\")\n",
    "    file_name = str(os.getcwd()) + '/emails/'\n",
    "    for i in file:\n",
    "        if(i!='b' and i!=\"'\"):\n",
    "            file_name = file_name + i\n",
    "    k+=1\n",
    "    file_reading = open(file_name,\"r\",encoding='utf-8', errors='ignore')\n",
    "    words_list_array = np.zeros(words.size)\n",
    "    for word in file_reading.read().split():\n",
    "        word = lmtzr.lemmatize(word.lower())\n",
    "        if(word in stopwords.words('english') or word in string.punctuation or len(word)<=2 or word.isdigit()==True):\n",
    "            continue\n",
    "        for i in range(words.size):\n",
    "            if(words[i]==word):\n",
    "                words_list_array[i] = words_list_array[i]+1\n",
    "                break\n",
    "    f = open(\"frequency.csv\",\"a\")\n",
    "    for i in range(words.size):\n",
    "        f.write(str(int(words_list_array[i])) + ',')\n",
    "    if(len(file_name)==68):\n",
    "        f.write(\"-1\")\n",
    "    elif (len(file_name)==71):\n",
    "        f.write(\"1\")\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "    if(k%100==0):\n",
    "        print(\"Done \" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfca7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (in seconds) to segregate entire dataset to form input vector 985.46\n"
     ]
    }
   ],
   "source": [
    "print(\"Time (in seconds) to segregate entire dataset to form input vector \" + str(round(time() - start_time,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
